\section{Tweet Searcher}

The Twitter Search API is a great choice since it allows narrow filtering based on localisation (delimitation of squares of research), as well as logical operators inside the query string. The API keeps track of the previous request sent in order to deliver only the newly indexed tweets while doing a callback. This is very suitable, since we don't need to keep tracks of tweets IDs to avoid duplicates. \\

The API also proposes a way to get more tweets by looking back into the past (one ping to the API returns at most 100 tweets, but it's possible to ask, in a second request, to get older data). Since we do not want to go too much in the past and since we assumed that we were already getting enough data without using this option, we discarded it. \\

The limitation of 450 tweets per 15 minutes is our biggest bottleneck in term of data. Fortunately the Searcher where designed to be able to search with multiple keys and learn which squares they should ask more often. They can also handle situations where the system is kicked by the API due to a heavy load, or in case of network failure. \\

Like the rest of our system, the searcher is built on the Akka Actor System and therefore interact with the other parts by message-passing. Depending on the properties of a machine or in case of multi-node deployment, the number of searchers can be significantly increased using simple parameters stored in the configuration files. Hence, the data source can scale. \\